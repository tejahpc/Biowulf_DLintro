{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qnyTxjK_GbOD"
   },
   "source": [
    "# Beyond Hello World, A Computer Vision Example\n",
    "\n",
    "In 01_HelloWorld.ipynb, you created a neural network that figured out the simple rule Y=2x-1 using data (learned behavior). Here, we'll apply deep learning on computer vision problem, where writing rules is much more difficult. Let's take a look at a scenario where we can recognize 10 different types of clothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H41FYgtlHPjW"
   },
   "source": [
    "## Import Libraries\n",
    "Let's start with our import of pytorch (torch), numpy, and skimage for transforming the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1577,
     "status": "ok",
     "timestamp": 1550587660097,
     "user": {
      "displayName": "Laurence Moroney",
      "photoUrl": "https://lh3.googleusercontent.com/-RcxktLY-TBk/AAAAAAAAAAI/AAAAAAAAABY/b4V4dTIqmPI/s64/photo.jpg",
      "userId": "06401446828348966425"
     },
     "user_tz": 480
    },
    "id": "q3KzJyjv3rnA",
    "outputId": "7a1ceed7-66f6-4a43-b3f4-26d54bd95817"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from skimage import transform\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n_n1U5do3u_F"
   },
   "source": [
    "## Provide Data\n",
    "For the data, we will be using Fashion MNIST ( https://github.com/zalandoresearch/fashion-mnist ), consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes/ types of clothes. The dataset is available from the torchvision library, which consists of popular datasets, model architectures, and common image transformations for computer vision.. You load it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PmxkHFpt31bM"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "trainset = datasets.FashionMNIST('/scratch/teja/F_MNIST_data/', download=True, train=True, transform=None)\n",
    "testset = datasets.FashionMNIST('/scratch/teja/F_MNIST_data/', download=True, train=False, transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rw395ROx4f5Q"
   },
   "source": [
    "Using matplotlib, we'll print a training image and its associated training label. Experiment with different indices in the array. For example, index 42 is a different boot than the one at index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1550587722332,
     "user": {
      "displayName": "Laurence Moroney",
      "photoUrl": "https://lh3.googleusercontent.com/-RcxktLY-TBk/AAAAAAAAAAI/AAAAAAAAABY/b4V4dTIqmPI/s64/photo.jpg",
      "userId": "06401446828348966425"
     },
     "user_tz": 480
    },
    "id": "FPc9d3gJ3jWF",
    "outputId": "5efae963-162d-4418-c001-2e8d6af83f40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Label: 9\n",
      "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
      "           0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,   1,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,   0,\n",
      "          36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,   0,   3],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,\n",
      "         102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,  10,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,  72,  15],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,  69,\n",
      "         207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88, 172,  66],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0, 200,\n",
      "         232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196, 229,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 183,\n",
      "         225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245, 173,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 193,\n",
      "         228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243, 202,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12, 219,\n",
      "         220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197, 209,  52],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99, 244,\n",
      "         222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119, 167,  56],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55, 236,\n",
      "         228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,  92,   0],\n",
      "        [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237, 226,\n",
      "         217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,  77,   0],\n",
      "        [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228, 207,\n",
      "         213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244, 159,   0],\n",
      "        [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217, 226,\n",
      "         200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238, 215,   0],\n",
      "        [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200, 159,\n",
      "         245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232, 246,   0],\n",
      "        [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,  80,\n",
      "         150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228, 225,   0],\n",
      "        [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217, 241,\n",
      "          65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224, 229,  29],\n",
      "        [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198, 213,\n",
      "         240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221, 230,  67],\n",
      "        [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219, 221,\n",
      "         220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205, 206, 115],\n",
      "        [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211, 210,\n",
      "         200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177, 210,  92],\n",
      "        [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189, 188,\n",
      "         193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216, 170,   0],\n",
      "        [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244, 221,\n",
      "         220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
      "       dtype=torch.uint8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aab19db4400>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "idx=0  # replace with 42\n",
    "print(\"Training Label: {}\".format(trainset.train_labels[idx]))\n",
    "print(trainset.train_data[idx])\n",
    "plt.imshow(trainset.train_data[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cbrdH225_nH"
   },
   "source": [
    "You'll notice that all of the values in the number are between 0 and 255. If we are training a neural network, for various reasons it's easier if the values are **normalized**. Here we use torchvision transforms to normalize the pixels and transform to torch tensor. We also define the batch size for the Dataloader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kRH19pWs6ZDn"
   },
   "outputs": [],
   "source": [
    "import os    # os is needed to use the SLURM_CPUS_PER_TASK environment from the slurm session\n",
    "# define the transformations\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    "# use fashion MNIST from the torchvision datasets but this time use transform defined above\n",
    "trainset = datasets.FashionMNIST('/scratch/teja/F_MNIST_data/', download=False, train=True, transform=transform)\n",
    "testset = datasets.FashionMNIST('/scratch/teja/F_MNIST_data/', download=False, train=False, transform=transform)\n",
    "# define batch size and use pytroch's dataloader for the data \n",
    "batch_size=1024 \n",
    "trainloader = DataLoader(trainset,batch_size=batch_size, shuffle=True,num_workers=int(os.environ['SLURM_CPUS_PER_TASK']))\n",
    "testloader = DataLoader(testset,batch_size=batch_size, shuffle=True,num_workers=int(os.environ['SLURM_CPUS_PER_TASK']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3DkO0As46lRn"
   },
   "source": [
    "## Define and Compile the Neural Network\n",
    "Let's now design the model. Things to note:\n",
    "\n",
    "Linear Module (**nn.Linear**) computes output from input using a linear function, and holds internal Tensors for its weight and bias.\n",
    "\n",
    "Each layer of neurons need an activation function to tell them what to do. There's lots of options, but just use these for now.\n",
    "\n",
    "**Relu** effectively means \"If X>0 return X, else return 0\" -- so what it does it it only passes values 0 or greater to the next layer in the network.\n",
    "\n",
    "**Softmax** takes a set of values, and effectively picks the biggest one, so, for example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it saves you from fishing through it looking for the biggest value, and turns it into [0,0,0,0,1,0,0,0,0] -- The goal is to save a lot of coding!\n",
    "\n",
    "Here, we create a nn.Module class named Net. The init function (defines input and number of neurons) and forward function (where the network makes a guess) are defined and the backward function (where gradients are computed) is automatically defined using autograd.\n",
    "\n",
    "Once the model is defined, we instantiate the model passing in .cuda if using the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7mAyndG3kVlK"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784,128)  # 28x28 = 784; 1st hidden layer has 128 neurons\n",
    "        self.fc2 = nn.Linear(128,10)   # input is 128 from fc1 and output layer has 10 units\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x,dim=1)\n",
    "        return x\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    net = Net().cuda()\n",
    "else:\n",
    "    net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c8vbMCqb9Mh6"
   },
   "source": [
    "## Train the Neural Network\n",
    "\n",
    "Training the neural network fits your training data to your training labels -- i.e. have it figure out the relationship between the training data and its actual labels so in future if you have data that looks like the training data, then it can make a prediction for what that data would look like. The training is contained in the loop over the number of epochs. This is where it will go through the loop making a guess (outputs), measuring how good or bad it is (aka the loss), calculating the gradients (loss.backward), and using the opimizer to make another guess etc. When you run this code, you'll see the loss on the right hand side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29548,
     "status": "ok",
     "timestamp": 1550587849991,
     "user": {
      "displayName": "Laurence Moroney",
      "photoUrl": "https://lh3.googleusercontent.com/-RcxktLY-TBk/AAAAAAAAAAI/AAAAAAAAABY/b4V4dTIqmPI/s64/photo.jpg",
      "userId": "06401446828348966425"
     },
     "user_tz": 480
    },
    "id": "BLMdl9aP8nQ0",
    "outputId": "91a80606-f0a5-41f0-9d03-91d1ecdc8e17",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Training Loss: 1.6198, Training Acc: 85.0117\n",
      "Epoch 2/50, Training Loss: 1.6122, Training Acc: 85.6533\n",
      "Epoch 3/50, Training Loss: 1.6078, Training Acc: 86.0683\n",
      "Epoch 4/50, Training Loss: 1.6029, Training Acc: 86.5283\n",
      "Epoch 5/50, Training Loss: 1.6010, Training Acc: 86.6050\n",
      "Epoch 6/50, Training Loss: 1.5981, Training Acc: 86.8983\n",
      "Epoch 7/50, Training Loss: 1.5951, Training Acc: 87.1517\n",
      "Epoch 8/50, Training Loss: 1.5920, Training Acc: 87.5517\n",
      "Epoch 9/50, Training Loss: 1.5885, Training Acc: 87.8917\n",
      "Epoch 10/50, Training Loss: 1.5873, Training Acc: 87.9233\n",
      "Epoch 11/50, Training Loss: 1.5846, Training Acc: 88.1767\n",
      "Epoch 12/50, Training Loss: 1.5831, Training Acc: 88.3683\n",
      "Epoch 13/50, Training Loss: 1.5808, Training Acc: 88.6167\n",
      "Epoch 14/50, Training Loss: 1.5795, Training Acc: 88.6817\n",
      "Epoch 15/50, Training Loss: 1.5775, Training Acc: 88.9200\n",
      "Epoch 16/50, Training Loss: 1.5749, Training Acc: 89.1183\n",
      "Epoch 17/50, Training Loss: 1.5747, Training Acc: 89.2250\n",
      "Epoch 18/50, Training Loss: 1.5720, Training Acc: 89.4700\n",
      "Epoch 19/50, Training Loss: 1.5706, Training Acc: 89.5583\n",
      "Epoch 20/50, Training Loss: 1.5696, Training Acc: 89.7000\n",
      "Epoch 21/50, Training Loss: 1.5684, Training Acc: 89.7967\n",
      "Epoch 22/50, Training Loss: 1.5668, Training Acc: 89.9133\n",
      "Epoch 23/50, Training Loss: 1.5655, Training Acc: 90.0817\n",
      "Epoch 24/50, Training Loss: 1.5639, Training Acc: 90.2483\n",
      "Epoch 25/50, Training Loss: 1.5632, Training Acc: 90.2983\n",
      "Epoch 26/50, Training Loss: 1.5614, Training Acc: 90.4367\n",
      "Epoch 27/50, Training Loss: 1.5605, Training Acc: 90.5300\n",
      "Epoch 28/50, Training Loss: 1.5598, Training Acc: 90.6133\n",
      "Epoch 29/50, Training Loss: 1.5585, Training Acc: 90.7167\n",
      "Epoch 30/50, Training Loss: 1.5576, Training Acc: 90.8667\n",
      "Epoch 31/50, Training Loss: 1.5556, Training Acc: 91.0583\n",
      "Epoch 32/50, Training Loss: 1.5554, Training Acc: 91.0600\n",
      "Epoch 33/50, Training Loss: 1.5553, Training Acc: 91.0617\n",
      "Epoch 34/50, Training Loss: 1.5537, Training Acc: 91.2617\n",
      "Epoch 35/50, Training Loss: 1.5537, Training Acc: 91.2133\n",
      "Epoch 36/50, Training Loss: 1.5534, Training Acc: 91.2333\n",
      "Epoch 37/50, Training Loss: 1.5517, Training Acc: 91.4000\n",
      "Epoch 38/50, Training Loss: 1.5506, Training Acc: 91.4750\n",
      "Epoch 39/50, Training Loss: 1.5497, Training Acc: 91.6733\n",
      "Epoch 40/50, Training Loss: 1.5497, Training Acc: 91.6317\n",
      "Epoch 41/50, Training Loss: 1.5496, Training Acc: 91.5933\n",
      "Epoch 42/50, Training Loss: 1.5469, Training Acc: 91.8833\n",
      "Epoch 43/50, Training Loss: 1.5468, Training Acc: 91.9083\n",
      "Epoch 44/50, Training Loss: 1.5457, Training Acc: 92.0500\n",
      "Epoch 45/50, Training Loss: 1.5459, Training Acc: 91.9650\n",
      "Epoch 46/50, Training Loss: 1.5453, Training Acc: 92.0817\n",
      "Epoch 47/50, Training Loss: 1.5455, Training Acc: 92.0000\n",
      "Epoch 48/50, Training Loss: 1.5460, Training Acc: 91.9633\n",
      "Epoch 49/50, Training Loss: 1.5454, Training Acc: 92.0417\n",
      "Epoch 50/50, Training Loss: 1.5433, Training Acc: 92.2033\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5;\n",
    "learning_rate = 0.001;\n",
    "\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()      # define loss \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)   # define optimizer\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    iter_loss = 0\n",
    "    correct = 0 \n",
    "    iterations = 0 \n",
    "    \n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images.resize_(images.size()[0],784)\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net.forward(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        iter_loss += loss.item() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Record the correct predictions for training data \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels.data).sum()\n",
    "        iterations += 1\n",
    "        \n",
    "    train_loss.append(iter_loss/iterations)\n",
    "    # Record the training accuracy\n",
    "    train_accuracy.append((100.0 * correct.cpu().numpy() / len(trainloader.dataset)))    # use numpy otherwise rounded up\n",
    "\n",
    "    print ('Epoch {}/{}, Training Loss: {:.4f}, Training Acc: {:.4f}'.format(epoch+1, num_epochs, train_loss[-1], train_accuracy[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-JJMsvSB-1UY"
   },
   "source": [
    "Notice how the loss decreases and the accuracy increases over time. Once training is done-- you should see an accuracy value at the end of the final epoch (~0.89). This tells you that your neural network is about 89% accurate in classifying the training data. I.e., it figured out a pattern match between the image and the labels that worked 89% of the time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model using unseen data\n",
    "\n",
    "We use the 10,000 test images to evaluate the model on unseen data. We can call **model.evaluate**, and pass in the two sets (images and labels), and it will report back the loss for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 832,
     "status": "ok",
     "timestamp": 1550587895553,
     "user": {
      "displayName": "Laurence Moroney",
      "photoUrl": "https://lh3.googleusercontent.com/-RcxktLY-TBk/AAAAAAAAAAI/AAAAAAAAABY/b4V4dTIqmPI/s64/photo.jpg",
      "userId": "06401446828348966425"
     },
     "user_tz": 480
    },
    "id": "WzlqsEzX9s5P",
    "outputId": "4dd8018a-f3ba-4e5b-e163-3d4f5dd12f19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 87.8500\n"
     ]
    }
   ],
   "source": [
    "net.eval()     # put the network into evaluating mode \n",
    "correct = 0\n",
    "for i, (images, labels) in enumerate(testloader):\n",
    "        images.resize_(images.size()[0],784)\n",
    "        images = Variable(images.cuda())\n",
    "        classes = Variable(labels.cuda())\n",
    "        outputs = net.forward(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == classes.data).sum()\n",
    "\n",
    "valid_accuracy= 100.0 * correct.cpu().numpy() / len(testloader.dataset)\n",
    "\n",
    "print ('Validation Accuracy: {:.4f}'.format(valid_accuracy))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6tki-Aro_Uax"
   },
   "source": [
    "For me, that returned an accuracy of about 0.86. As expected, the model probably would not do as well with *unseen* data as it did with data it was trained on!  \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Course 1 - Part 4 - Lesson 2 - Notebook.ipynb",
   "provenance": [
    {
     "file_id": "1yhyaHJIeyutXBuE2HmViuD-tV5EMqzUG",
     "timestamp": 1547798065395
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
