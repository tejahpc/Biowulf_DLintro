{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZIAkIlfmCe1B"
   },
   "source": [
    "# The Hello World of Deep Learning with Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fA93WUy1zzWf"
   },
   "source": [
    "Summary:\n",
    "\n",
    "- Simple script showing overall scaffolding for how Pytorch code works\n",
    "- Use neural networks to learn the relationship between two numbers\n",
    "- Feed set of Xs and Ys to neural network to determine relationship/rule\n",
    "\n",
    "In the example, the function is: y = 2x -1. Using data, we are training a neural network to figure out the relationship between X and Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DzbtdRcZDO9B"
   },
   "source": [
    "## Imports\n",
    "\n",
    "Importing libraries needed to run the simple neural network including torch and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X9uIpOS2zx7k"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5QyOUhFw1OUX"
   },
   "source": [
    "## Providing the Data\n",
    "\n",
    "Next we'll use numpy to generate some data with 6 xs and 6ys. The relationship between x and y is that y=2x-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Dxk4q-jzEy4"
   },
   "outputs": [],
   "source": [
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=np.float32).reshape(-1,1)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=np.float32).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwJGmDrQ0EoB"
   },
   "source": [
    "## Define and Compile the Neural Network\n",
    "\n",
    "Next we will create the simplest possible neural network, which has 1 layer (in this case nn.Linear). The input shape to the layer is just 1 value and the layer has 1 neuron.  \n",
    "\n",
    "In pytorch, neural networks can be constructed using torch.nn package. Here, we create a nn.Module class named Net. The init function and forward function (where the network makes a guess) are defined and the backward function (where gradients are computed) is automatically defined using autograd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQFAr_xo0M4T"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(1,1)     # initializing a linear network with 1 input and 1 neuron, respectively\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KhjZjZ-c0Ok9"
   },
   "source": [
    "Now we instantiate our Neural Network. If using GPUs, we also specify the model runs on the GPU device. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m8YQN1H41L-Y"
   },
   "outputs": [],
   "source": [
    "model = Net()  # instantiate the neural network\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a loss and an optimizer to our Neural Network.  \n",
    "\n",
    "We know that in our function is y=2x-1. When the computer is trying to 'learn', it makes a guess (maybe y=10x+10). The LOSS function measures how close the guessed answers is to the known correct answers.\n",
    "\n",
    "It then uses the OPTIMIZER function to make another guess, while trying to minimize the loss (e.g., y=5x+5, which, while still pretty bad, is closer to the correct result and has lower loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using mean squared error for the loss function\n",
    "criterion = nn.MSELoss()   \n",
    "# using stochastic gradient descent for the optimizer\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n_YcWRElnM_b"
   },
   "source": [
    "# Training the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c-Jk4dG91dvD"
   },
   "source": [
    "The process of training the neural network, where it 'learns' the relationship between the Xs and Ys is contained in the loop over the number of epochs. This is where it will go through the loop making a guess (outputs), measuring how good or bad it is (aka the loss), calculating the gradients (loss.backward), and using the opimizer to make another guess etc. When you run this code, you'll see the loss on the right hand side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lpRrl7WK10Pq"
   },
   "outputs": [],
   "source": [
    "for epoch in range(2000):\n",
    "#    for i, data in enumerate(train_loader,0):\n",
    "#        inputs, labels = data\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = Variable(torch.from_numpy(xs).cuda())   # if using gpu, pass in inputs and labels to the GPU device\n",
    "        labels = Variable(torch.from_numpy(ys).cuda())\n",
    "    else:\n",
    "        inputs = Variable(torch.from_numpy(xs))\n",
    "        labels = Variable(torch.from_numpy(ys))\n",
    "    optimizer.zero_grad()                               # zero the parameter gradients\n",
    "    outputs = model(inputs)                             # initial prediction                        \n",
    "    loss = criterion(outputs,labels)                    # define loss\n",
    "    loss.backward()                                     # calculate gradient\n",
    "    optimizer.step()                                    # take optimizer step\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the training progesses, the loss decreases. After training, we are plotting the predicted values (dots) compared to the actual values (line) for the set of x's used in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "with torch.no_grad(): # we don't need gradients in the testing phase\n",
    "    if torch.cuda.is_available():\n",
    "        predicted = model(Variable(torch.from_numpy(xs).cuda())).cpu().data.numpy()   # GPU version\n",
    "    else:\n",
    "        predicted = model(Variable(torch.from_numpy(xs))).data.numpy()                # non-GPU version\n",
    "    print(predicted)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(xs, predicted, 'go', label='Predictions', alpha=0.5)\n",
    "plt.plot(xs, ys, '--', label='True Data', alpha=0.5)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kaFIr71H2OZ-"
   },
   "source": [
    "## Use model to predict unseen value of x\n",
    "\n",
    "Now that you have a model trained to learn the X-Y relationship. You can use the model to figure out the Y for a previously unknown X (e.g., 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oxNzL4lS2Gui"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "test = np.array([10.0], dtype=np.float32).reshape(-1,1)     # need to reshape data to feed to the neural network\n",
    "model(Variable(torch.from_numpy(test).cuda())).cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "btF2CSFH2iEX"
   },
   "source": [
    "The prediction ended up slightly under 19. Why?\n",
    "\n",
    "Remember that neural networks deal with probabilities, so given the data that we fed the NN with, it calculated that there is a very high probability that the relationship between X and Y is Y=2X-1, but with only 6 data points we can't know for sure. As a result, the result for 10 is very close to 19, but not necessarily 19.\n",
    "\n",
    "To determine how the predictions are made, we can look at the internal variables of the Dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"These are the weights used: {}\".format(list(model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the weights 1.92 and -0.78 are close to 2x -1. Increasing the number of epochs should improve the predictions. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Colab1-for-deeplearn.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
