{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZIAkIlfmCe1B"
   },
   "source": [
    "# The Hello World of Deep Learning with Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fA93WUy1zzWf"
   },
   "source": [
    "##### Summary: \n",
    "* Simple script showing overall scaffolding for how Tensorflow code works \n",
    "* Use neural networks to learn the relationship between two numbers\n",
    "* Feed set of Xs and Ys to neural network to determine relationship/rule\n",
    "\n",
    "In the example, the function is: y = 2x -1. Using data, we are training a neural network to figure out the relationship between X and Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DzbtdRcZDO9B"
   },
   "source": [
    "## Import Libraries\n",
    "\n",
    "First, we need to importing tensorflow and other libraries:\n",
    "- TensorFlow and calling it *tf* for ease of use\n",
    "- Numpy, which helps us to represent data as lists easily and quickly\n",
    "- Keras, the framework for defining a neural network as a set of Sequential layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X9uIpOS2zx7k"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5QyOUhFw1OUX"
   },
   "source": [
    "## Provide Data\n",
    "\n",
    "Next we'll use numpy to generate some data with 6 xs and 6ys. The relationship between x and y is that y=2x-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Dxk4q-jzEy4"
   },
   "outputs": [],
   "source": [
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwJGmDrQ0EoB"
   },
   "source": [
    "## Define and Compile the Neural Network\n",
    "\n",
    "Next we will create the simplest possible neural network, which has 1 layer (keras.layers.Dense). That layer has 1 neuron (units=1), and the input shape to it is just 1 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQFAr_xo0M4T"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KhjZjZ-c0Ok9"
   },
   "source": [
    "We compile the Neural Network specifying 2 functions, a loss and an optimizer. \n",
    "\n",
    "We know that in our function is y=2x-1. When the computer is trying to 'learn', it makes a guess (maybe y=10x+10). The **LOSS** function measures how close the guessed answers is to the known correct answers.\n",
    "\n",
    "It then uses the **OPTIMIZER** function to make another guess, while trying to minimize the loss (e.g., y=5x+5, which, while still pretty bad, is closer to the correct result and has lower loss).\n",
    "\n",
    "While there are many choices, in this example we use mean squared error for loss and Stochastic Gradient Descent for optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m8YQN1H41L-Y"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mean_squared_error')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c-Jk4dG91dvD"
   },
   "source": [
    "## Train the Neural Network\n",
    "\n",
    "With the model defined and compiled, **model.fit** is the process of training the neural network, where it 'learns' the relationship between the Xs and Ys. This is where it will go through the loop of making a guess, measuring how good or bad it is (loss), using the opimizer to make another guess etc. It will do it for the specified number of **epochs**. One epoch is when an entire dataset (here the 6 numbers in Xs) is passed both forward and backward through the neural network only once. \n",
    "\n",
    "Note: the loss is shown on the right hand side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lpRrl7WK10Pq"
   },
   "outputs": [],
   "source": [
    "model.fit(xs, ys, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 500 epochs, the loss went from ~47.8 (a really bad guess) to ~0.00006 (where the differences between the predicted and actual values are small)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kaFIr71H2OZ-"
   },
   "source": [
    "## Use model to predict unseen value of x\n",
    "\n",
    "Ok, now you have a model trained to learn the X-Y relationship. You can use the **model.predict** method to have it figure out the Y for a previously unknown X (e.g., 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oxNzL4lS2Gui"
   },
   "outputs": [],
   "source": [
    "unknown_x=10.0\n",
    "print(model.predict([unknown_x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "btF2CSFH2iEX"
   },
   "source": [
    "The prediction ended up slightly under 19. Why? \n",
    "\n",
    "Remember that neural networks deal with probabilities, so given the data that we fed the NN with, it calculated that there is a very high probability that the relationship between X and Y is Y=2X-1, but with only 6 data points we can't know for sure. As a result, the result for x=10 is very close to 19, but not necessarily 19. \n",
    "\n",
    "To determine how the predictions are made, we can look at the internal variables of the Dense layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The internal variables used: {}\".format(model.get_weights()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the weight and bias 1.996 and -0.989 are close to 2x -1 (you might get slightly different values here). \n",
    "\n",
    "Now, let's see what happens if we extend our neural network by adding more neurons. Here we define model2, which use a hidden layer with 3 neurons (l0) and an output layer (l1) that gives use one output, the predicted value of Y. **tf.keras.Sequential** defines a SEQUENCE of layers in the neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0 = tf.keras.layers.Dense(units=3, input_shape=[1])         # layer with 3 neurons and an input of 1 x value\n",
    "l1 = tf.keras.layers.Dense(units=1)                          # output layer\n",
    "model2 = tf.keras.Sequential([l0, l1])                       # define the neural network with the 2 layers\n",
    "model2.compile(optimizer='sgd', loss='mean_squared_error')   # compile the neural network with loss and optimizer defined\n",
    "model2.fit(xs, ys, epochs=500)                               # training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss is smaller compared to the model with 1-neuron layer. Now let's predict the value of Y if x = 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_x=10.0\n",
    "print(\"The prediction for 10 is {}\".format(model2.predict([unknown_x])))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, adding more layers and neurons seem to improve the prediction . And looking at the internal variables of the layers we see a more complicated set of weights and biases as opposed to the near 2x-1 relation with 1 neuron. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"These are the internal variables for the hidden layer with 3 neurons: {}\".format(l0.get_weights()))\n",
    "print(\"These are the internal variables for layer1: {}\".format(l1.get_weights()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the internal variables predict Y? We  multiply the input number with the layer weights from the hidden layer (l0) and add the l0 bias and use the output and apply the weights and biases in the output layer (l1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0_sum=unknown_x*l0.get_weights()[0]+l0.get_weights()[1]                    # multiply input number with l0 layer weights and add l0 bias\n",
    "print(\"Hidden layer value= {}\".format(l0_sum))\n",
    "l1_sum=np.sum(l0_sum*np.transpose(l1.get_weights()[0])) + l1.get_weights()[1]  # multiply the output for l0 layer to l1 weights and add l1 bias \n",
    "print(\"Output layer value= {0:.15f}\".format(l1_sum[0]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This shows how the prediction was obtained based on the input (unknown_x=10) and the internal variables from the trained model. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Colab1-for-deeplearn.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
